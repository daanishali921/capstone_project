{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "20adad52",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "343471e8-b215-4bfc-84c3-4eb888c30cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "import os\n",
    "import subprocess\n",
    "\n",
    "import json\n",
    "import csv\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from datetime import datetime, date, time\n",
    "\n",
    "import snscrape.modules.twitter as sntwitter\n",
    "import yfinance as yf\n",
    "\n",
    "import re\n",
    "\n",
    "import time\n",
    "\n",
    "import glob\n",
    "\n",
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2568faf2",
   "metadata": {},
   "source": [
    "## scrapeTweets() and dataWrangle() functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8293af13-b4ea-42ad-a7d0-a2fb9326be41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep note of directory_name -- it is based on the stock in question of the form tweets_(STOCK_NAME)\n",
    "# example: tweets_GME or tweets_TSLA\n",
    "\n",
    "def scrapeTweets(start, stop, keyword, directory, tweet_limit=1):\n",
    "    if not os.path.exists(directory): # Creates directory in current directory if doesn't already exist\n",
    "        os.mkdir(directory)\n",
    "    \n",
    "    file_path = os.path.join(directory, f'keyword:{keyword}__start:{start}_end:{stop}__limit:{tweet_limit}.csv')\n",
    "    \n",
    "    tweet_list = []\n",
    "    for i,tweet in enumerate(sntwitter.TwitterSearchScraper(f'{keyword} since:{start} until:{stop}').get_items()):\n",
    "        if i > tweet_limit:\n",
    "            break\n",
    "        tweet_list.append([tweet.date, # Appending all tweet data into a list of list\n",
    "                           tweet.id, \n",
    "                           tweet.content, \n",
    "                           tweet.user.username, \n",
    "                           tweet.user.followersCount, \n",
    "                           tweet.hashtags, \n",
    "                           tweet.cashtags, \n",
    "                           tweet.lang])\n",
    "    \n",
    "    df_tweets = pd.DataFrame(tweet_list, columns=['Datetime', # Creating df of tweet data\n",
    "                                                  'Tweet Id', \n",
    "                                                  'Text', \n",
    "                                                  'Username', \n",
    "                                                  'Followers Count', \n",
    "                                                  'Hashtags', \n",
    "                                                  'Cashtags', \n",
    "                                                  'Language'])\n",
    "    \n",
    "    df_tweets.to_csv(file_path, index=False) # Writing df_tweets into new csv file\n",
    "    \n",
    "    if os.path.isfile(file_path) == True:\n",
    "        return print(f'Successfully saved DataFrame to {file_path}')\n",
    "    else:\n",
    "        return print('DataFrame not saved -- possible error has occurred.')        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d5dfebb5-6eb1-4b19-8686-9dcc43579714",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating function to clean dataframes programatically\n",
    "\n",
    "\n",
    "def dataWrangle(dataframe_list):   \n",
    "    df_concat = pd.concat(dataframe_list) # Concatenate all the DataFrames from the list of DataFrames\n",
    "    df_filter = df_concat[df_concat['Language'] == 'en'][['Datetime', # Filter via Language = 'en'\n",
    "                                                           'Tweet Id', # Remove unwanted columns\n",
    "                                                           'Text', \n",
    "                                                           'Username',\n",
    "                                                           'Followers Count']] \n",
    "    df_clean = df_filter.astype({'Tweet Id':str})\\\n",
    "                        .dropna()\\\n",
    "                        .drop_duplicates()\\\n",
    "                        .reset_index(drop=True)\n",
    "    \n",
    "    df_clean['Text'] = (df_clean['Text'] # Cleans out redundant string characters within each tweet\n",
    "                       .apply(lambda x: ' '.join(re.sub(r'https\\S+', '', x)\n",
    "                                                .replace('\\n', ' ')\n",
    "                                                .split()\n",
    "                                                )\n",
    "                             )\n",
    "                       )\n",
    "    \n",
    "    return df_clean\n",
    "                                               "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07671159",
   "metadata": {},
   "source": [
    "## Creating DataFrames of Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "434410a9-9c53-429f-9e88-64eae627eee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of file names\n",
    "\n",
    "# Files from two directories -- scraped at different time irl \n",
    "# for the same dates within the data\n",
    "\n",
    "file_path_tweets_GME = glob.glob('tweets_GME/*')\n",
    "file_path_tweets_scraped = glob.glob('tweets_scraped/*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8cf0313a-1ff8-4be7-9e0a-9fb3c5c289bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a list of DataFrames using glob's list of files names\n",
    "df_list = []\n",
    "for i in file_path_tweets_GME + file_path_tweets_scraped:\n",
    "    df_list.append(pd.read_csv(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fbf82f3f-f0a5-48eb-a84e-e2fac6d89e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = date(2021, 1, 8).strftime('%Y-%m-%d')\n",
    "stop_time = date(2021, 2, 12).strftime('%Y-%m-%d')\n",
    "\n",
    "def toDateTimeIndex(df): # year-month-day\n",
    "    df['Datetime'] = pd.to_datetime(df['Datetime']).dt.floor('d').dt.tz_localize(tz=None)\n",
    "    df.index = pd.DatetimeIndex(df['Datetime']) # Can use .set_index(<column name>) instead to make function a one liner\n",
    "    df = df.drop(columns=['Datetime'])\n",
    "    return df.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "83032170-f296-4f59-bfd6-80b42e4cfc08",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dataWrangle(df_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f1aa140e-a2df-44a4-8088-7652d13a1b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Datetime'] = pd.to_datetime(df['Datetime']).dt.floor('d').dt.tz_localize(tz=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a01ac4fb",
   "metadata": {},
   "source": [
    "## Polarity Scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "155d2439",
   "metadata": {},
   "source": [
    "A list of goals to accomplish: \\\n",
    "    - Figure out polarity/subjectivity scores for every tweet\\\n",
    "    - For now we want to work with dates from 01/21/2021 and onwards as a test\\\n",
    "    - Mess about with distribution of negative/positive/neutral scores to have a healthy balance of samples\\\n",
    "    - Break everything up by days\\\n",
    "    - Move onto bringing in financial data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3ec2cad2-4a7f-4ae5-82fd-55b262b96dcd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df['Polarity/Subjectivity Scores'] = df['Text'].apply(lambda text: TextBlob(text).sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b8b7047f-fc62-4c73-8215-1a2372bad726",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pol_clean = df[df['Polarity/Subjectivity Scores'] != (0.0,0.0)].set_index('Datetime').sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fafcad8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Datetime</th>\n",
       "      <th>Tweet Id</th>\n",
       "      <th>Text</th>\n",
       "      <th>Username</th>\n",
       "      <th>Followers Count</th>\n",
       "      <th>Polarity/Subjectivity Scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-01-08</td>\n",
       "      <td>1347684080905814016</td>\n",
       "      <td>$GME NEW ARTICLE : GameStop Is Caught in a Vic...</td>\n",
       "      <td>StckPro</td>\n",
       "      <td>4198</td>\n",
       "      <td>(-0.09090909090909091, 0.6886363636363636)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-01-08</td>\n",
       "      <td>1347683977327497217</td>\n",
       "      <td>@RamBhupatiraju @richard_chu97 @saxena_puru @F...</td>\n",
       "      <td>tmyrbrgh</td>\n",
       "      <td>263</td>\n",
       "      <td>(0.0, 0.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-01-08</td>\n",
       "      <td>1347681621953159169</td>\n",
       "      <td>GameStop Is Caught in a Vicious Cycle $GME $TG...</td>\n",
       "      <td>newsfilterio</td>\n",
       "      <td>20861</td>\n",
       "      <td>(-1.0, 1.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-01-08</td>\n",
       "      <td>1347637710866030592</td>\n",
       "      <td>@michaeljburry what are your thought on what s...</td>\n",
       "      <td>JohnMOFOThomas</td>\n",
       "      <td>5</td>\n",
       "      <td>(0.225, 0.625)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-01-08</td>\n",
       "      <td>1347618202612760576</td>\n",
       "      <td>@ryancohen Can't stop, won't stop, GameStop! C...</td>\n",
       "      <td>AeternumLibera</td>\n",
       "      <td>36</td>\n",
       "      <td>(0.0, 0.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106623</th>\n",
       "      <td>2021-02-05</td>\n",
       "      <td>1357705012919508995</td>\n",
       "      <td>@carlquintanilla @CNBC They Stopped Us Again, ...</td>\n",
       "      <td>BleezyforSheezy</td>\n",
       "      <td>131</td>\n",
       "      <td>(0.5, 0.6)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106624</th>\n",
       "      <td>2021-02-05</td>\n",
       "      <td>1357705010222673923</td>\n",
       "      <td>$GME said</td>\n",
       "      <td>prodigenoir</td>\n",
       "      <td>848</td>\n",
       "      <td>(0.0, 0.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106625</th>\n",
       "      <td>2021-02-05</td>\n",
       "      <td>1357705006724620290</td>\n",
       "      <td>$GME and $AMC halted 🤨</td>\n",
       "      <td>tweek3634</td>\n",
       "      <td>24</td>\n",
       "      <td>(0.0, 0.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106626</th>\n",
       "      <td>2021-02-05</td>\n",
       "      <td>1357705004996517891</td>\n",
       "      <td>BUY #AMC and #GME 💎🙌🚀🦍🍌 (not financial advice)</td>\n",
       "      <td>YoSheenn</td>\n",
       "      <td>201</td>\n",
       "      <td>(0.0, 0.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106627</th>\n",
       "      <td>2021-02-05</td>\n",
       "      <td>1357705003385970695</td>\n",
       "      <td>$GME going crazy again 😄</td>\n",
       "      <td>momchev12</td>\n",
       "      <td>653</td>\n",
       "      <td>(-0.6, 0.9)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>106628 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Datetime             Tweet Id  \\\n",
       "0      2021-01-08  1347684080905814016   \n",
       "1      2021-01-08  1347683977327497217   \n",
       "2      2021-01-08  1347681621953159169   \n",
       "3      2021-01-08  1347637710866030592   \n",
       "4      2021-01-08  1347618202612760576   \n",
       "...           ...                  ...   \n",
       "106623 2021-02-05  1357705012919508995   \n",
       "106624 2021-02-05  1357705010222673923   \n",
       "106625 2021-02-05  1357705006724620290   \n",
       "106626 2021-02-05  1357705004996517891   \n",
       "106627 2021-02-05  1357705003385970695   \n",
       "\n",
       "                                                     Text         Username  \\\n",
       "0       $GME NEW ARTICLE : GameStop Is Caught in a Vic...          StckPro   \n",
       "1       @RamBhupatiraju @richard_chu97 @saxena_puru @F...         tmyrbrgh   \n",
       "2       GameStop Is Caught in a Vicious Cycle $GME $TG...     newsfilterio   \n",
       "3       @michaeljburry what are your thought on what s...   JohnMOFOThomas   \n",
       "4       @ryancohen Can't stop, won't stop, GameStop! C...   AeternumLibera   \n",
       "...                                                   ...              ...   \n",
       "106623  @carlquintanilla @CNBC They Stopped Us Again, ...  BleezyforSheezy   \n",
       "106624                                          $GME said      prodigenoir   \n",
       "106625                             $GME and $AMC halted 🤨        tweek3634   \n",
       "106626     BUY #AMC and #GME 💎🙌🚀🦍🍌 (not financial advice)         YoSheenn   \n",
       "106627                           $GME going crazy again 😄        momchev12   \n",
       "\n",
       "       Followers Count                Polarity/Subjectivity Scores  \n",
       "0                 4198  (-0.09090909090909091, 0.6886363636363636)  \n",
       "1                  263                                  (0.0, 0.0)  \n",
       "2                20861                                 (-1.0, 1.0)  \n",
       "3                    5                              (0.225, 0.625)  \n",
       "4                   36                                  (0.0, 0.0)  \n",
       "...                ...                                         ...  \n",
       "106623             131                                  (0.5, 0.6)  \n",
       "106624             848                                  (0.0, 0.0)  \n",
       "106625              24                                  (0.0, 0.0)  \n",
       "106626             201                                  (0.0, 0.0)  \n",
       "106627             653                                 (-0.6, 0.9)  \n",
       "\n",
       "[106628 rows x 6 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b98568b8-7985-4396-aa73-fc2ef2de96fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sorted_dates = df_pol_clean[\"2021-01-21\":][['Text', 'Polarity/Subjectivity Scores']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fcc785fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Polarity/Subjectivity Scores</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-01-21</th>\n",
       "      <td>So, Dr. Burry, some free advice for a good guy...</td>\n",
       "      <td>(0.15555555555555559, 0.6611111111111111)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-21</th>\n",
       "      <td>@LizClaman @GameStop @ClamanCountdown Liz, And...</td>\n",
       "      <td>(-0.18787878787878784, 0.4055555555555555)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-21</th>\n",
       "      <td>@FarisBakkar @Long_GME E-commerce growth for G...</td>\n",
       "      <td>(0.05833333333333335, 0.4583333333333333)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-21</th>\n",
       "      <td>@FarisBakkar @Long_GME You are honestly recycl...</td>\n",
       "      <td>(0.049999999999999975, 0.5083333333333333)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-21</th>\n",
       "      <td>UPDATE: Citron's Andrew Left On GameStop Short...</td>\n",
       "      <td>(0.075, 0.3989583333333333)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-02-11</th>\n",
       "      <td>@KChampbell @2009Michael1984 Just think if Blo...</td>\n",
       "      <td>(0.05393939393939393, 0.4242424242424243)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-02-11</th>\n",
       "      <td>@aurban22 @RocketCatchnBob Yes, you should be ...</td>\n",
       "      <td>(0.45, 0.7866666666666667)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-02-11</th>\n",
       "      <td>My retarded question is, since diamond hands a...</td>\n",
       "      <td>(-0.2, 0.45)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-02-11</th>\n",
       "      <td>Cannabis stocks lit up as the Reddit rally dro...</td>\n",
       "      <td>(0.18181818181818182, 0.5)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-02-11</th>\n",
       "      <td>@ajeyehassan You realise it won't hit $1 right...</td>\n",
       "      <td>(0.2392857142857143, 0.5865079365079365)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>73990 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                         Text  \\\n",
       "Datetime                                                        \n",
       "2021-01-21  So, Dr. Burry, some free advice for a good guy...   \n",
       "2021-01-21  @LizClaman @GameStop @ClamanCountdown Liz, And...   \n",
       "2021-01-21  @FarisBakkar @Long_GME E-commerce growth for G...   \n",
       "2021-01-21  @FarisBakkar @Long_GME You are honestly recycl...   \n",
       "2021-01-21  UPDATE: Citron's Andrew Left On GameStop Short...   \n",
       "...                                                       ...   \n",
       "2021-02-11  @KChampbell @2009Michael1984 Just think if Blo...   \n",
       "2021-02-11  @aurban22 @RocketCatchnBob Yes, you should be ...   \n",
       "2021-02-11  My retarded question is, since diamond hands a...   \n",
       "2021-02-11  Cannabis stocks lit up as the Reddit rally dro...   \n",
       "2021-02-11  @ajeyehassan You realise it won't hit $1 right...   \n",
       "\n",
       "                          Polarity/Subjectivity Scores  \n",
       "Datetime                                                \n",
       "2021-01-21   (0.15555555555555559, 0.6611111111111111)  \n",
       "2021-01-21  (-0.18787878787878784, 0.4055555555555555)  \n",
       "2021-01-21   (0.05833333333333335, 0.4583333333333333)  \n",
       "2021-01-21  (0.049999999999999975, 0.5083333333333333)  \n",
       "2021-01-21                 (0.075, 0.3989583333333333)  \n",
       "...                                                ...  \n",
       "2021-02-11   (0.05393939393939393, 0.4242424242424243)  \n",
       "2021-02-11                  (0.45, 0.7866666666666667)  \n",
       "2021-02-11                                (-0.2, 0.45)  \n",
       "2021-02-11                  (0.18181818181818182, 0.5)  \n",
       "2021-02-11    (0.2392857142857143, 0.5865079365079365)  \n",
       "\n",
       "[73990 rows x 2 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sorted_dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "307b4f5b-f557-4b20-902a-96e70bfb873c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def binaryPolarity(tup):\n",
    "    if tup[0] < -0.1:\n",
    "        return 'Negative'\n",
    "    elif tup[0] > 0.1:\n",
    "        return 'Positive'\n",
    "    else:\n",
    "        return 'Neutral'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "f22a0b3f-f0a9-428c-a443-6c6673df07a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def binaryPolarity(tup):\n",
    "    if tup[0] < 0:\n",
    "        return 'Negative'\n",
    "    elif tup[0] > 0:\n",
    "        return 'Positive'\n",
    "    else:\n",
    "        return 'Neutral'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "b5a66b16-d08a-4605-a7e4-182b552d0b22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Neutral'"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binaryPolarity(df_sorted_dates['Polarity/Subjectivity Scores'][12312])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "3334299e-dd5d-4959-b3a9-e87b2296b52d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sorted_dates['Polarity Categories'] = df_sorted_dates['Polarity/Subjectivity Scores'].apply(lambda x: binaryPolarity(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "2f6b76ce-a42f-4056-8edd-78e99e6fa88b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Polarity Categories\n",
       "Positive    34678\n",
       "Neutral     25397\n",
       "Negative    13915\n",
       "dtype: int64"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sorted_dates.value_counts('Polarity Categories')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "78f749ab-d1e7-43a7-9133-9799ef3f3160",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Polarity Categories\n",
       "Positive    44135\n",
       "Negative    21719\n",
       "Neutral      8136\n",
       "dtype: int64"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sorted_dates.value_counts('Polarity Categories')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a3cde34-c349-4fbf-bb5d-5ba8295d0b41",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "capstone_kernel",
   "language": "python",
   "name": "capstone_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
